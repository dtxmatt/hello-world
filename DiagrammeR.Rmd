---
title: "DiagrammeR Documentation Streams"
author: "Matthew Blanchard"
date: "2/27/2021"
output: rmdformats::html_clean
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


#  {.tabset .tabset-pills}
## Overview 

Implement a way to represent dependencies between functions, which allows us to manage how we understand, interact with, and document data transformation processes. Dual goal of enabling information needed for conversion to data.table and any related design choices.

The desired outcome will lessen conceptual overhead for future contributors who are trying to understand the impacts of code updates. **That is the primary goal.** This process needs to be understandable and simple to interface with so that it is used and can be updated with confidence in a shorter amount of time.

In order to facilitate developmental goals in the implementation of this process, one idea is to meet with either my supervisor or some other third party periodically and explain/review the process and the code underlying it. This would not replace any final review / quality testing, just a way to get input on "big picture" design choices and whether it feels intuitive. Additional time spend on preparing materials for that would be intended to make sure the process stays well documented and explainable.

Goals: Analytic Process Improvement - make our knowledge more accessible and more flexible.

## Directed Graphs

Given raw data $\mathbf{X}$, we can define a data wrangling process 
$\mathbf{T} \ \colon \ \mathbf{X} \ \mapsto \ \mathbf{X^{\prime}}$,
where $\mathbf{X^{\prime}}$ contains the additional transformed variables we want to work with.

We can represent this process as a directed graph. A graph structure visualizes how we divide a task into different functions. This would inform design judgement during translation. 

**What would this look like?**

  * Each vertex in the graph is a **function**
    + Some functions would be stand-alone nodes (casting, 1-1 transforms)
    + Some functions may have external inputs (mapping tables)
    + Some functions may point at other functions, where $(1) \rightarrow (2)$ implies $(2)$ uses the output of $(1)$. 
    + Each node is named after the function it represents. 
    + Each node can be imbued with an arbitrary data structure to contain function definition, function documentation, input/output expectation, etc.
        
  * Essentially a **dependency diagram**, where dependencies between functions form **tree structures**. 
    + Still have "flat" representation of code distributed across separate function files, but we need a documentation structure to show how they're related.
  * **Traversals** can be used to organize quality testing and to query information about the process.
    + Given a map of function dependencies, you can also think about a "dual" map of inputs to outputs, where each transformed variable has an arrow pointing to it from each element of its preimage. Will need to make sure there's a way to traverse the graph to organize inputs/outputs as well.
    
Some other desirable features:

  * Graph structures are well understood data structures, common to use base library implementations of this structure in other domains.
  * Generalized representation of the process is flexible. We need information in a general form in case packages or other interfaces with the data change.

## Implementation

The following defines the directed graph of interest:

  * **Nodes** $(f_1, f_2, ..., f_n)$ represent data transformation function calls. 
    + Since dependencies exist, we have a pre-defined **order** for the functions $\mathbf{T} \ = \ f_n \ \circ \ f_{n-1} \ \circ \ \ldots \ \circ \ f_1$.
    + Order really only matters if the function is a part of a non-trivial tree
  * **Directed edges** $(e_1, e_2, ..., e_m)$, where edge $e_k$ connects functions $f_i$ and $f_j$ to imply $f_j$ depends on the results of $f_i$.  
    + Adjacency matrix $\mathbf{A}_{m{\times}m}$ for $m$ vertices.
    + Each edge $e_k := I(f_i, f_j)$ has a corresponding entry in $\mathbf{A}_{m{\times}m}[i,j]$, where $I()$ indicates an arrow points from function i to function j.
    
You only need the order of function execution to perform the transformation. However, the additional graph structure gives more capabilities.

Using a graph definition, we can construct parallel processes that run along-side the primary function calls during the actual data transform. 

I.e. each helper function could have an optional setting that could enable additional calls (DiagrammeR calls). That way if you are running *the* class plan data transform, you can enable that option and produce an in-time documentation of the transformation you just did that is visually accessible. Ad-hoc development updates and tests would require having these additional calls turned off since we're not running the entire process all at once.

## Example Data { .tabset .tabset-pills}

---

### Raw Data 
```{r}
library(data.table)
x_raw = data.table(a = 1:10, b = round(runif(10)), c = rep(c("A","B"),5))
x_raw
```


### Function List {.tabset .tabset-pills}
```{r, echo=FALSE}
library(knitr)
#install.packages("devtools")
#devtools::install_github("haozhu233/kableExtra")
library(kableExtra)

kable(data.table(function.names = c("function1.R", "function2.R", "function3.R"), description = c("Converts a to score f(a)", "Maps f(a)", "Casting"))) %>% kable_classic(html_font = "cambria", full_width = F)
```

---

#### Function 1
```{r}
function1 = function(x_raw) {x_raw[,f.a := 10^(1+log10(a))]}
```


#### Function 2
```{r}
function2 = function(x_raw) {x_raw[, a.class := ifelse(f.a<5, "Yes", "No")]}
```


#### Function 3
```{r}
function3 = function(x_raw) {x_raw[,newc := ifelse(c == "A", "Yes", ifelse(b==1,"Yes","No"))]}
```

### Transformed data
```{r}
function1(x_raw)
function2(x_raw)
function3(x_raw)
x_raw
```

## DiagrammeR {.tabset .tabset-pills}

[DiagrammeR](http://rich-iannone.github.io/DiagrammeR/docs.html) is a package that can provide the tools needed to implement this framework. It's stability across time should be evaluated, but I'll note that a lot of the package value is in visualizations. It seems unlikely that future package updates and R versions would break the basic graph algorithm structure underlying everything in the package, though.

Any implementation of DiagrammeR would rest on top of a complete product. You can always default back to running through the data transforms linearly and have the code as documentation. That will never break. And the edge/node data frames generated are general enough for translation to other applications.

---

### Example Function Attributes

Now lets recreate the prior example in DiagrammeR
```{r}
library(DiagrammeR)
library(magrittr)
# Remember - this is all just dressing up of an ordered list of function executions

## First lets conceptually recreate all the needed information for the functions
function.list = c("function1.R", "function2.R", "function3.R")
function.desc = c("Converts a to score f(a)", "Maps f(a)", "Casting")

## If there's a way to programmatically extract function details from their source files, even better. Can be manually specified
function.details = list(
  list(# Function 1
    "Imports" = "",
    "Dependencies" = "function2",
    "Input Fields" = "a",
    "Output Fields" = "f.a"
  ),
  list(# Function 2
    "Imports" = "function1",
    "Dependencies" = "",
    "Input Fields" = "f.a",
    "Output Fields" = "a.class"
  ),
  list(# Function 3
    "Imports" = "",
    "Dependencies" = "",
    "Input Fields" = "b,c",
    "Output Fields" = "newc"
  )
)
```

### Example Graph Creation

```{r, figure.width = 8}
## Create the "nodes" data.frame
## Putting a helper function pattern needed to massage the list data
extract_field = function(y) {unname(unlist(sapply(seq_along(function.list), function(x) {function.details[[x]][y]})))}

nodes = create_node_df(
    n = length(function.list),
    type = "Transform",
    label = function.list,
    description = function.desc,
    imports = extract_field("Imports"),
    depends = extract_field("Dependencies"),
    inputs = extract_field("Input Fields"),
    outputs = extract_field("Output Fields"))
nodes


## Create the "edges" data.frame
## Can auto-generate by looking at each row in the matrix and concatenating into from/to columns, but hardcoding for simplicity

edges = create_edge_df(
  from = 1,
  to = 2,
  rel = "receives",
  data = "f.a"
)
edges

graph = create_graph(nodes_df = nodes, edges_df = edges)
render_graph(graph, output = "visNetwork")


```

### Example Traversals

Let's say function1 has undergone some changes and we want to check if any corresponding updates are required in other functions.

Find all nodes with an arrow coming from 1 to themselves. This just shows you can use the node attributes that express information about the function.
```{r}
tmp = graph %>%
  select_nodes(
    conditions = imports == "function1")

tmp %>% get_selection()
```  


### Adjacency Matrix Equivalent

To show off desireable generality of this representation.

```{r}
## 1 points at 2
ex.adj = matrix(c(0,1,0,
                  0,0,0,
                  0,0,0), nrow = 3)
graph = from_adj_matrix(ex.adj)
render_graph(graph, output = "visNetwork")
```


Bigger example
```{r}
adj_matrix <-
  sample(
    0:1, 100,
    replace = TRUE,
    prob = c(0.9,0.1)
  ) %>%
  matrix(ncol = 10)
graph <- from_adj_matrix(adj_matrix, mode = "directed")
render_graph(graph, output = "visNetwork")
```
